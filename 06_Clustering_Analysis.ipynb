{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec548556",
   "metadata": {},
   "source": [
    "# Clustering Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7c61c8",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276063b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "features = ['Close', 'High', 'Low', 'Open', 'Volume']\n",
    "X = balanced_df[features]\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "dbscan = DBSCAN(eps=0.4, min_samples=5)\n",
    "clusters = dbscan.fit_predict(X_pca)\n",
    "\n",
    "balanced_df['DBSCAN_Cluster'] = clusters\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "palette = sns.color_palette('husl', len(set(clusters)))\n",
    "sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=clusters, palette=palette, legend='full')\n",
    "plt.title('DBSCAN Clustering Results (PCA-reduced Data)', fontsize=16)\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.legend(title='Cluster')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "n_clusters = len(set(clusters)) - (1 if -1 in clusters else 0)\n",
    "n_noise = list(clusters).count(-1)\n",
    "\n",
    "if n_clusters >= 2:\n",
    "    print(f'DBSCAN found {n_clusters} clusters.')\n",
    "    print(f' Number of noise points: {n_noise}')\n",
    "    mask = clusters != -1\n",
    "    sil_score = silhouette_score(X_scaled[mask], clusters[mask])\n",
    "    print(f' Silhouette Score (excluding noise): {sil_score:.4f}')\n",
    "else:\n",
    "    print(f'DBSCAN found {n_clusters} cluster(s). Silhouette score not defined.')\n",
    "    print(f'Number of noise points: {n_noise}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c547e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "k = 5\n",
    "neigh = NearestNeighbors(n_neighbors=k)\n",
    "nbrs = neigh.fit(X_scaled)\n",
    "distances, indices = nbrs.kneighbors(X_scaled)\n",
    "\n",
    "k_distances = np.sort(distances[:, -1])\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_distances)\n",
    "plt.title(f'K-distance Graph (k={k})')\n",
    "plt.xlabel('Points sorted by distance')\n",
    "plt.ylabel(f'{k}th Nearest Neighbor Distance')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7740e39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = balanced_df[['DBSCAN_Cluster']].copy()\n",
    "cluster_labels['Target'] = y.values\n",
    "\n",
    "cluster_analysis = cluster_labels.groupby('DBSCAN_Cluster')['Target'].value_counts(normalize=True).unstack()\n",
    "print('Class distribution in each cluster:\n",
    "')\n",
    "print(cluster_analysis.fillna(0).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e98ebe",
   "metadata": {},
   "source": [
    "## K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fd48e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "features = ['Close', 'High', 'Low', 'Open', 'Volume']\n",
    "X = balanced_df[features]\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "k = 4\n",
    "kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "clusters_kmeans = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "balanced_df['KMeans_Cluster'] = clusters_kmeans\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "palette = sns.color_palette('husl', k)\n",
    "sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=clusters_kmeans, palette=palette, legend='full')\n",
    "plt.title('K-Means Clustering Results (PCA-reduced Data)', fontsize=16)\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.grid(True)\n",
    "plt.legend(title='Cluster')\n",
    "plt.show()\n",
    "\n",
    "sil_score = silhouette_score(X_scaled, clusters_kmeans)\n",
    "ari_score = adjusted_rand_score(balanced_df['Target'], clusters_kmeans)\n",
    "\n",
    "print(f'Silhouette Score: {sil_score:.4f}')\n",
    "\n",
    "cluster_target_dist = balanced_df.groupby('KMeans_Cluster')['Target'].value_counts(normalize=True).unstack().fillna(0)\n",
    "print('\n",
    "Target Proportions in Each K-Means Cluster:')\n",
    "print(cluster_target_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c0189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "features = ['Close', 'High', 'Low', 'Open', 'Volume']\n",
    "X = balanced_df[features]\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "inertia_scores = []\n",
    "silhouette_scores = []\n",
    "k_range = range(2, 11)\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    clusters = kmeans.fit_predict(X_scaled)\n",
    "    inertia_scores.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X_scaled, clusters))\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(k_range, inertia_scores, marker='o', linestyle='-')\n",
    "plt.title(' Elbow Method (Inertia)')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(k_range, silhouette_scores, marker='s', color='green')\n",
    "plt.title(' Silhouette Scores')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b17857",
   "metadata": {},
   "source": [
    "## Agglomerative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c5e25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "features = ['Close', 'High', 'Low', 'Open', 'Volume']\n",
    "X = balanced_df[features]\n",
    "y = balanced_df['Target']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "linked = linkage(X_scaled, method='ward')\n",
    "\n",
    "n_clusters = 3\n",
    "agg = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward')\n",
    "clusters = agg.fit_predict(X_scaled)\n",
    "\n",
    "balanced_df['Hierarchical_Cluster'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2790f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "palette = sns.color_palette('Set1', n_clusters)\n",
    "sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=clusters, palette=palette, legend='full')\n",
    "plt.title('Hierarchical Clustering Results (PCA-reduced Data)', fontsize=16)\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.legend(title='Cluster')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f840daaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sil_score = silhouette_score(X_scaled, clusters)\n",
    "ari_score = adjusted_rand_score(y, clusters)\n",
    "\n",
    "print(f' Silhouette Score: {sil_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7eaabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_counts = pd.crosstab(balanced_df['Hierarchical_Cluster'], y, normalize='index')\n",
    "print('Target Proportions in Each Hierarchical Cluster:')\n",
    "print(cluster_counts)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
